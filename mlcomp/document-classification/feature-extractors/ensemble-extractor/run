#! /usr/bin/env python

#./run construct extractor1 extractor2 ... extractorN
#./run extract <path to datashard> <output file>

import sys
from subprocess import call
from os import chdir, getcwd
from collections import defaultdict
import cPickle as pickle

def saveState():
    pickle.dump([extractors, num, featureMaps], open('ensemble-extractor-savedstate.pickle', 'w'))
    #human readable savestate
    f = open('ensemble-extractor-savedstate.txt', 'w')
    f.write('extractors = %s\n' % extractors)
    f.write('num = %s\n' % num)
    f.write('featureMaps = %s\n' % [sorted(x.items()) for x in featureMaps])
    f.close()

def nextInt():
    global num
    num += 1
    return num

args = sys.argv
operation = args[1] #construct, extract, or cleanup
if operation == 'construct':
    extractors = args[2:] #space separated list of paths to extractors (folders containing run files)
    num = 0
    featureMaps = []
    for i in range(len(extractors)):
        featureMaps.append(defaultdict(nextInt))
    saveState()
    sys.exit(0)

assert(operation == 'extract')

#load saved state
extractors, num, featureMaps = pickle.load(open('ensemble-extractor-savedstate.pickle', 'r'))
inpath = args[2] #path of datashard
outf = args[3] #output file

cwd = getcwd()

extractions = []
for i, extractor in enumerate(extractors):
    chdir(extractor)
    if call(['./run', 'extract', cwd + '/' + inpath, '%s.tmp' % i]) != 0:
        print extractor, 'failed'
        print 'exiting'
        sys.exit(-1)
    extractions.append([x.strip().split(' ') for x in open('%s.tmp' % i, 'r').readlines()])
    chdir(cwd)

outf = open(outf, 'w')
for i in range(len(extractions[0])):
    outf.write('%s ' % extractions[0][i][0])
    for extraction, featureMap in zip(extractions, featureMaps):
        idxs_vals = [x.split(':') for x in extraction[i][1:]]
        outf.write('%s ' % ' '.join(['%s:%s' % (featureMap[idx], val) for idx, val in idxs_vals]))
    outf.write('\n')

outf.close()
saveState()